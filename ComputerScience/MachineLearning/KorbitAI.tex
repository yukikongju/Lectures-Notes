\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{textgreek}
\begin{document}
\title{Lecture Notes for KorbitAI}
\author{Emulie Chhor}
\maketitle

\section*{Introduction}

\newtheorem{definition}{Definition}[subsection]
\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{corollary}{Corollary}[subsection]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{axiom}{Axiome}
\newtheorem{property}{Propriété}[subsection]
\newtheorem*{remark}{Remarque}
\newtheorem*{problem}{Problème}
\newtheorem*{intuition}{Intuition}

\begin{enumerate}
    \item Data Science Basics Path
    \item Probability Basics Path
    \item Linear Regression Path
    \item Classification Path
    \item CART Decision Trees Path
    \item Data Preprocessing Path
    \item Foundational ML Theory Path
    \item Unsupervised Learning Path
    \item Machine Learning Overview Path
    \item Introduction to Neural Networks Path
    \item Training Neural Netowrks Path
    \item Convolutional and Recurrent Neural Networks Path
\end{enumerate}


\section{Data Science Basics Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Descriptive Statistics
    \item Introduction to Graphs
    \item What is a Dataset
    \item Exploratory Data Analysis
\end{enumerate}

\section{Probability Basics Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Discrete vs Continuous Random Variable
    \item Expected Value vs Sample Mean
    \item Variance and Standard Deviation
    \item Binomial Distribution
    \item Normal Distribution
\end{enumerate}

\section{Linear Regression Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Regression
    \item Correlation
    \item Linear Regression
    \item Interpolation vs Extrapolation
    \item Evaluation Metrics
    \item Linear Regression with Categorical Features
    \item Conditions for Linear Regression
    \item Handling Outliers in Linear Regression
\end{enumerate}

\section{Classification Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Classification
    \item Binary Classification
    \item Logistic Regression Basics
    \item Sigmoid Function
    \item Evaluation Metrics (classification)
    \item Binary Classification for Imbalanced Classes
    \item Naive Bayes Classifier
    \item K-nearest Neighbors
\end{enumerate}

\section{CART Decision Trees Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Introduction to Decision Trees
    \item CART Decision Tree Splits
    \item Decision Tree Selection Criteria
    \item Introduction to Random Forests
\end{enumerate}

\section{Data Preprocessing Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Overview of Data Preprocessing
    \item Data Cleaning
    \item Handling Outliers
    \item Feature Engineering
    \item One-Hot Encoding
    \item Feature Importance
    \item Feature Selection
    \item Feature Scaling
    \item Dimensionality Reduction
    \item Principal Component Analysis
\end{enumerate}

\section{Foundational ML Theory Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Cost and Loss Functions
    \item Splitting Data
    \item Cross Validation
    \item Parameters vs Hyperparameters
    \item Hyperparameters Tuning
    \item Overview of Regularization
    \item L1 vs L2 regularization
\end{enumerate}

\section{Unsupervised Learning Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Unsupervised Learning
    \item Clustering
    \item K-Means Clustering
\end{enumerate}

\section{Machine Learning Overview Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Supervised Learning
    \item Linear Approximators
    \item Generalized Linear Approximators
    \item Overfitting and Underfitting
    \item Bias and Variance: Cross-Validation
    \item Bias-Variance Decomposition
    \item Overview of Logistic Regression
    \item Gradient Descent
    \item Regulatization for Logistic Regression
    \item Lecture Summary: Intro to ML
\end{enumerate}

\section{Introduction to Neural Networks Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item The Rise of Deep Learning
    \item An Artificial Neuron
    \item Example: 'OR' Neuron Using Sigmoid Activation
    \item Example: Neuron with Rectified Linear Function
    \item One-Layer Neural Network
    \item Example: 'XOR' Neural Network
    \item Deep Training Neural Networks
    \item Lecture Summary: Introduction to Training Neural Networks
\end{enumerate}

\section{Training Neural Netowrks Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Stochastic Gradient Descent
    \item The Backpropagation Algorithm
    \item Optimization Difficulties
    \item Optimization Algorithms
    \item Visualizing how a Neural Network is Trainied
    \item Example: Data Preprocessing
    \item Overview of Model Selection
    \item Lecture Summary: Training Neural Netorks
\end{enumerate}

\section{Convolutional and Recurrent Neural Networks Path}
\subsection{Overview}%
\label{sub:Overview}

\begin{enumerate}
    \item Object Detection Task
    \item Overview of Convolutional Training Neural Networks
    \item Convolutional Training Neural Networks: Convolutional Layers
    \item Convolutional Training Neural Networks: Pooling Layers
    \item Convolutional Training Neural Networks: Complete Object Detection Model
    \item Sentiment Classification Task
    \item Reccurent Neural Networks
    \item Deep Reccurent Neural Networks
    \item Lecture Summary: Convolutional and Reccurent Training Neural Networks
\end{enumerate}

\section{Ressources}%
\label{sec:Ressources}

- KorbitAI

\end{document}
\end{article}

