\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{parskip}
\usepackage{textgreek}
\begin{document}
\title{Notes de Cours MAT1720 - Probabilités}
\author{Emulie Chhor}
\maketitle

\section*{Introduction}

Le premier cours de probabilité comporte 4 chapitres:

\begin{enumerate}
    \item Introduction aux Probabilités
    \item Variables Aléatoires
    \item Espérance de Variables Aléatoires
    \item Fonctions Génératrices et Théorème Limite Central
\end{enumerate}

\newtheorem{definition}{Definition}[subsection]
\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{corollary}{Corollary}[subsection]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{axiom}{Axiome}
\newtheorem{property}{Propriété}[subsection]
\newtheorem*{remark}{Remarque}
\newtheorem*{problem}{Problème}
\newtheorem*{intuition}{Intuition}

\section{Introduction à la Probabilité}

\subsection*{Overview}

Le premier chapitre porte sur les notions de bases en Probabilité.
On introduit la notion de dénombrement, la règle de Bayes et la
notion d'indépendance.\\

Il est essentiel de maitriser ces notions puisque les concepts des
autres chapitres seront basées sur celles-ci.

\subsection{Définition Classique de Probabilité}

La définition classique de probabilité nous dit qu'on peut trouver la
probabilité en considérant le ratio entre la cardinalité de notre
espace et la cardinalité de l'univers des possibles. En d'autres mots,
c'est le ratio entre les évènements favorables et tous les évènements.

\subsection{Règles de dénombrement}

\begin{enumerate}
    \item Principe de multiplication
    \item Principe d'addition
\end{enumerate}

La principe de multiplication et d'addition nous dit que lorsqu'on doit
multiplier les évènements consécutifs ensemble, alors que le principe
d'addition nous dit d'additionner la probabilité d'évènements disjoints.
On verra plus tard que le principe d'addition pourra se généraliser avec
le principe d'inclusion-exclusion.

En ce qui attrait le principe de multiplication, je trouve qu'il est
utile de visualiser chaque position comme des petites cases qu'on
doit déterminer la probabilité à chaque case.

\begin{problem}[Permutations et Combinaisons avec et sans remise]
    Souvent, les problèmes ne nous disent pas s'il s'agit d'un
    problème sans remise ou avec remise ou si l'ordre est important.
    Le plus important est de rester cohérent avec notre stratégie de
    dénombrement. Si on décide de compter le nombre de groupes, alors
    il faut rester avec le nombre de groupes. On ne peut pas calculer
    le nombre de groupe pour l'un et le nombre de personnes pour l'autre
\end{problem}

\subsection{Règles de dénombrement II}

\begin{enumerate}
    \item Permutations
    \item Combinaisons
    \item Boules et Urnes
\end{enumerate}

\subsubsection{Permutations}%
\label{ssub:permutations}

Les permutations comptent le nombre d'évènements en considérant l'ordre.
$$ P(n,r) = \frac{n!}{(n-r)!} $$ avec n: nombre d'éléments, r: nombre de cases\\

Intuitivement, le numérateur nous dit qu'on a n cases et qu'on doit piger
1 boule sans remise à chaque position, alors que le dénominateur nous dit
qu'on a compter trop de cases et qu'on doit retrancher les positions qu'on
a compter de trop.

\subsubsection{Combinaisons}%
\label{ssub:combinaisons}

Les combinaisons comptent le nombre d'évènements sans considérer l'ordre
de la pige et est donné par
$$ C(n,r) = \frac{n!}{r! (n-r)!} $$

Intuitivement, le nombre de combinaisons est le nombre de permutations dont
on a retrancher les groupes équivalents, donné par r!

\begin{problem}[Compter le nombre de paires]
    Lorsqu'on doit dénombrer de paires, on doit considérer la position de la
    paire et la sortes. Exemples:
    \begin{enumerate}
        \item Souliers: paires + gauche/droite
	\item Cartes: valeur + enseigne
    \end{enumerate}
\end{problem}

\subsubsection{Boules et Urnes}%
\label{ssub:boules_et_urnes}

Le principe de boules et urnes nous dit qu'on veut placer n boules dans r
urnes. Dépendamment des problèmes, on accepte que certaines urnes soients
vides ou non. Pour ma part, j'aime représenter les urnes avec des petites
boites. Parfois, certains problèmes plus tricky requiert qu'on dissecte
le problème en plusieurs étapes. On doit dabord fixer des positions, puis
résoudre avec l'astuce de boule et urnes par la suite.

\begin{problem}[Code Binaire]
\end{problem}

\subsection{Règles de dénombrement III}

\begin{enumerate}
    \item Formule de Pascal
    \item Formule du Binome
    \item Coefficients Binomiaux
\end{enumerate}

\subsection{Espaces de Probabilité}

\begin{enumerate}
    \item Espace Fondamental
\end{enumerate}

Un espace de probabilité est l'univers des possibles, c-à-d toutes les
valeurs que l'évènement X peut prendre. On note 3 axiomes importants, duquel
découlent tous les autres:

\begin{enumerate}
    \item $ \mathbb{P} (\Omega) = 1 $
    \item $ \mathbb{P} (A^c) = 1  - \mathbb{P}(A)$
\end{enumerate}

\subsubsection{Propriété de l'Espace Fondamental}%
\label{ssub:Propriété de l'Espace Fondamental}


\begin{property}[Propriétés de l'Espace fondamental]
    \item Propriété d'additivité
    \item Continuité croissante/décroissante
    \item Additivité Dénombrables
    \item Inégalité de Boole
    \item Propriété de Monotécité
\end{property}

\subsubsection{Principe d'inclusion-exclusion}%
\label{ssub:Principe d'inclusion-exclusion}

Le principe d'inclusion-exclusion nous permet de caluler la probabilité
de l'union (et de l'intersection) d'évènements qui ne sont pas disjoints.

Pour mieux comprendre, on peut dessiner un diagramme de Venne. Essentiellement, la formule nous dit qu'on doit retrancher les intersections pour éviter
de compter le même espace deux fois.

\subsection{Probabilité Conditionnelle}

\begin{enumerate}
    \item Définition
    \item Formule de Bayes
    \item Conditionnement
\end{enumerate}


\subsubsection{Définition de la Probabilité Conditionnelle}%
\label{ssub:Définition de la Probabilité Conditionnelle}

Intuitivement, la définition de la probabilité conditionnelle nous dit
que si on sait qu'une partie de l'espace fondamental s'est déjà produit,
alors on n'a plus besoin de le considérer (car ça s'est déjà passé), et
on peut le retrancher de la probabilité

\subsubsection{Formule de Bayes}%
\label{ssub:Formule de Bayes}

La formule de Bayes nous dit nous permet de calculer de la probabilité
à postériori. En observant un résultat, on peut faire de l'inférence pour
peut-être obtenir plus d'information sur une prieure.\\

On peut retrouver la formule en faisant l'égalité entre 2 probabilités
conditionnelles.

\subsection{Indépendance}

\begin{enumerate}
    \item Pairwise Independance
    \item Indépendance
    \item Conditionnement
\end{enumerate}

On peut interpréter l'indépendance de la façon suivante: connaitre
le résultat de X n'affecte pas la probabilité de Y. En d'autres mots,
si je pige X avant Y, je ne change pas la probabilité de Y. Connaitre
le résultat de X ne me donne pas plus d'information sur Y.\\

On sait que deux évènements (ou plus) sont indépendant si:
\begin{enumerate}
    \item Pairwise Independance: la probabilité de chaque paire est
	égale à la probabilité de leur intersection
    \item Independance "for all": la probabilité de l'intersection
	entre A,B,C est égale à leur produit
\end{enumerate}

Notons qu'on veut déterminer l'indépendance entre 2 variables, car ça
nous permet d'additionner des v.a. (prochain chapitre)

\section{Variables aléatoires}

\subsection*{Overview}

On étudie les variables aléatoires parce qu'on n'est pas capable
de déterminer la "chance" d'obtenir un résultat précis en un seul essai.
Par contre, si on répète l'expérience assez de fois, on est en mesure
d'estimer la probabilité d'un évènement

Le chapitre sur les variables aléatoires se découlent en:
\begin{enumerate}
    \item Variables aléatoires discrètes: valeur discrete
    \item Variables aléatoires continues: valeur continue
    \item Somme et Produit de Variable
    \item Transformation de variable aléatoire
    \item V.a. Conditionnelles
\end{enumerate}

Il faut aussi se souvenir qu'une v.a. est définie par la fonction densité,
représentant la courbe de sa valeur, et par sa fonction de répartition,
la valeur de sa probabilité, équivalent à l'aire sous la courbe.\\

Notons que les concepts du premier chapitre sont encore valide. Ce chapitre
essait de généraliser les résultats du premier chapitres. Ainsi, on
sait que l'aire sous la courbe est de 1.

\subsection{Variables aléatoires discrètes}

\subsection{Définition}

Une variable aléatoire discrète est une variable qui modélise un évènement
dont la valeur est discrète. Ici, on désire déterminer:
\begin{enumerate}
    \item Probabilité que X prenne une valeur quelconque: $ P(X = x)$
    \item Probabilité que X prenne une valeur dans un intervalle:
	$ P(X \leq x) $ ou $ P(X \geq x) = 1 - P(X \leq x)$ ou
	$ P(n < X < m) $
\end{enumerate}

Ainsi, si on veut déterminer la proba que X prenne la valeur 1 ou 2 ou ...,
on n'a qu'à additioner ses probabilités là.\\

Il existe plusieurs variables aléatoires discrètes, qui modélise des
situations différentes, et elles se trouvent avec les techniques de
dénombrement vues au chapitre 1.

\subsection{Loi de Variables aléatoires discrètes}

\begin{enumerate}
    \item Épreuves de Bernouilli
    \item Loi Binomiale
    \item Loi Géométrique
    \item Loi Hypergéométrique
    \item Loi Binomiale Négative
    \item Loi de Poisson
    \item Processus de Poisson
\end{enumerate}

\subsubsection{Épreuves de Bernouilli}%
\label{ssub:Épreuves de Bernouilli}

Malgré qu'on ne la considère pas comme une loi, une épreuve de Bernouilli
réprésente la probabilité d'un succès ou d'un échec pour un seul essai.

$$ P(I) = \text{ 1 * proba succès + 0 * proba échec } $$

On verra plus tard qu'on l'appelle aussi une variable indicatrice, et nous
aide à calculer les calculer la somme de variables aléatoires.

\subsubsection{Loi Binomiale}%
\label{ssub:Loi Binomiale}

La Binomiale est une généralisation de la Bernouilli. On veut déterminer
la probabilité d'avoir k succès en n épreuves. Une hypothèse de la binomiale
est que la probabilité de chaque succès est la même.\\

La formule de la binomiale est assez intuitive. Si la probabilité de succès
est donnée par p, alors on sait que la probabilité d'échec est de (1-p).
De plus, on a k succès et n-k échecs. Ainsi, on a
$$ p^k (1-p)^{n-k} $$, qu'on multiplie par la combinaisons, car l'ordre
n'importe pas.

Notons que si p est petit et n est grand, on peut modéliser avec une poisson
(on verra plus tard pourquoi)

\subsubsection{Loi Géométrique}%
\label{ssub:Loi Géométrique}

La loi géométrique représente la probabilité d'avoir le premier succès au
k-ième essai. Elle suppose aussi que la probabilité de succès est la
même à chaque essai (tirage avec remise).

Intuitivement, la formule peut être interpréter de la façon suivante:
si on veut que le premier succès soit à la k-ième position, on doit
fixer la k-ième position à un succès et les autres à un échec.
$$ P(X) = (1-p)^n p $$

Notons qu'on ne multiplie pas par la combinaison parce que ici, l'ordre
est important

\textbf{Pourquoi dit-on que la géométrique est sans mémoire}

On dit que la géométrique est sans mémoire, car elle ne dépend pas des
résultats précédants. Connaitre l'historique ne nous donne pas plus
d'information sur ce qu'il va se passer dans le futur: on n'a besoin que
de l'étape précédante

\subsubsection{Hypergéométrique}%
\label{ssub:Hypergéométrique}

Une distribution hypergéométrique détermine la probabilité d'avoir k succès
en n épreuves, mais dans un tirage sans remise.

$$ P(X=x) = \frac{\binom{(a,x) \binom(N-a, n-x) }}{\binom(N,n)} $$

Avec
\begin{enumerate}
    \item n: nombre objets
    \item a: nombre de succes
    \item X: nombre de succès dans le sample
\end{enumerate}

Le dénominateur représente le nombre de façon de piger n objets et le
numérateur représente le nombre de façon d'avoir x succès parmi les a
succès possibles x la proba d'avoir n-x échecs

\subsubsection{Binomiale Négative}%
\label{ssub:Binomiale Négative}

La binomiale négative est la distribution qui nous donne la distribution
du nombre d'essais requis pour avoir le r-ième succès avec probabilité p.


Pour obtenir la binomiale négative, on doit d'abord fixer le k-ème succès
au x-ième essais. $$p$$

Puis, il faut qu'il y ait (r-1) succès dans les (x-1)
essais (essais avant le k-ième succès). On sait aussi que l'ordre n'importe
pas, alors on doit multiplier par la combinaison. (utiliser l'intuition de la
binomiale)

$$ \binom{x-1, r-1} p^{r-1}(1-p)^{(x-1)-(r-1)} $$

On obtient donc

$$ P(X =x) = p x \binom{x-1, r-1} p^{r-1}(1-p)^{(x-1)-(r-1)}
= \binom{x-1, r-1} p^{r}(1-p)^{(x-r)} $$

\subsubsection{Poisson}%
\label{ssub:Poisson}

TODO

La loi de Poisson mesure le nombre d'évènements dans un intervalle donné.

\subsection{Variables aléatoires continues}

\subsection{Définition}

\begin{enumerate}
    \item Fonction de Densité
    \item Fonction de Répartition
\end{enumerate}

\subsection{Loi de Variables aléatoires continues}

\begin{enumerate}
    \item Loi Uniforme
    \item Loi Exponentielle
    \item Loi Normale
    \item Loi Log-Normale
    \item Loi Gamma
    \item Loi Chi-Deux
    \item Loi Cauchy
\end{enumerate}

\subsection{Variables aléatoires simultanées}

\subsection{Définitions v.a. discrètes}

\begin{enumerate}
    \item Fonction de Masse Conjointe
    \item Fonction de Masse Marginale
    \item Fonction de Masse Conditionnelle
\end{enumerate}

\subsection{Définitions v.a. continues}

\begin{enumerate}
    \item Fonction de Densité Conjointe
    \item Fonction de Densité Marginale
    \item Fonction de Densité Conditionnelle
\end{enumerate}

\subsection{Variables aléatoires Indépendates}

\subsection{Somme de Variables Aléatoires}
\subsection{Transformation de Variables Aléatoires}

\section{Espérance de Variables Aléatoires}
\subsection*{Overview}

\section{Fonction Génératrice et Théorème Limite Central}
\subsection*{Overview}

\subsection{Fonction Génératrice}

\subsection{Théorèmes Limites}

\subsection{Loi des Grands Nombres}
\subsection{Théorème Limite Central}
\subsection{Inégalité de Bienyamé-Tchebychev}

\end{document}
\end{article}
